# 基于预训练BERT的中文医疗关系抽取实践

## 介绍

### 任务介绍

中文医疗关系分类任务，旨在从中文医疗文本中识别并分类不同类型的医疗关系，这些关系通常涉及药物、症状、疾病、治疗方法等实体之间的联系。例如，该任务可能需要识别并分类“药物-治疗疾病”、“症状-诊断疾病”或“疾病-引发并发症”等关系类型，是个多分类问题。通过训练模型识别并分类这些关系，可以帮助构建医疗知识图谱，支持智能诊断、医学研究和健康信息管理等应用，有助于提升医疗数据的利用效率和准确性。数据例子如下所示：

| **句子**                                                                                                               | **头实体**       | **尾实体**     | **关系** |
| ---------------------------------------------------------------------------------------------------------------------------- | ---------------------- | -------------------- | -------------- |
| （二）婴儿**上消化道出血**常见原因：吞入母血、反流性食管炎、**应激性溃疡**、胃炎、出血性疾病以及Mallory-Weiss综合征。 | **上消化道出血** | **应激性溃疡** | **病因** |

### 数据集介绍

本数据集分为训练集、测试集和测试集三个 jsonl 文件，分别包含 7000、2000、1000 条数据。

* 每条数据包括：句子id、头实体、尾实体、关系、句子。
* 关系类别有 10 类，每个类别包含 1000 条数据，其中关系类别分别为：临床表现、药物治疗、同义词、病因、并发症、病理分型、实验室检查、辅助治疗、相关（导致）、影像学检查。

数据格式示例如下所示：

```
{
  "id": 0, 
  "sentence": "早期先天性梅毒多见于早产儿、低出生体重儿或小于胎龄儿;生后的发育、营养状况落后于同胎龄儿。⑥中枢神经系统症状:在新生儿期罕见，多在生后3~6个月时出现脑膜炎症状,脑脊液中淋巴细胞数增高，蛋白呈中度增高，糖正常。", 
  "h": "先天性梅毒", 
  "t": "脑膜炎症状", 
  "r": "临床表现"
}
```

## 环境配置

* pytorch
* transformers
* scikit-learn
* Other common packages

## 食用方法

1. 配置环境
2. 运行 python train.py 进行训练，训练好的模型保存在checkpoint路径下。
3. 运行 python test.py 进行测试。

## 代码实现思路

这是一个简单的关系分类任务，在数据集中提供了句子和待抽取关系的头、尾实体，同时限制了关系类别为有限的10类，因此我们可以使用预训练BERT进行关系（文本）分类。因为是中文任务，我选择的是中文BERT [hfl/chinese-roberta-wwm-ext · Hugging Face](https://huggingface.co/hfl/chinese-roberta-wwm-ext)。

在训练中，使用 `transformers` 库的 `BertForSequenceClassification` 类加载BERT可以很容易的实现在文本分类任务上的微调和推理。
我使用这个方法在训练数据上进行微调，并尝试了5种训练语句的编码方式。

| 文本编码方式   | 具体实现                                                                                        |
| -------------- | ----------------------------------------------------------------------------------------------- |
| Basic1         | [CLS] {h} [SEP] {sentence} [SEP] {t}                                                            |
| Basic2         | [CLS] {h} [SEP] {t} [SEP] {sentence}                                                            |
| QA             | [CLS] {h}和{t}之间的关系是什么？[SEP] {sentence}                                                |
| Entity_marked1 | [CLS]{sentence-part1}[E1]{h}[/E1]{sentence-part2}[E2]{t}[/E2]{sentence-part3}[SEP]              |
| Entity_marked2 | [CLS]{sentence-part1}[实体1]{h}[/实体1]{sentence-part2}[实体2]{t}[/实体2] {sentence-part3}[SEP] |

具体请见 [基于预训练大语言模型BERT的关系抽取方法](基于预训练大语言模型BERT的关系抽取方法.pdf)
